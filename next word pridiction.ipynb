{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d1d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a33777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = open(\"metamorphosis.txt\", 'r',encoding=\"latin1\")\n",
    "lines = []\n",
    "for i in files:\n",
    "    lines.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd62d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Metamorphosis\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b9fe1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "for i in lines:\n",
    "    data = \" \".join(lines)\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace(r'\\uteff', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1799d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Metamorphosis      This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, y'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb3c5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translater = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "new_data = data.translate(translater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2580c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Metamorphosis      This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever  You may copy it  give it away or re use it under the terms of the Project Gutenberg License included with this ebook or online at www gutenberg org  If you are not located in the United States  y'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data.translate(translater)\n",
    "new_data[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46db6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for i in data.split():\n",
    "    if i not in new:\n",
    "        new.append(i)\n",
    "data = \" \".join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76a809ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Metamorphosis This ebook is for the use anyone anywhere in United States and most other parts world at no cost with almost restrictions whatsoever. You may copy it, give it away or re-use under terms License included this online www.gutenberg.org. If you are not located States, will have to check laws country where before using eBook. *** a COPYRIGHTED Details Below. Please follow copyright guidelines file. Title: Author: Franz Kafka Translator: David Wyllie Release date: August 17, 2005 [eBook #5200] Most recently updated: April 28, 2021 Language: English START OF THE PROJECT GUTENBERG EBOOK METAMORPHOSIS by Translated I One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed his bed into horrible vermin. He lay on armour-like back, if lifted head little could see brown belly, slightly domed divided arches stiff sections. bedding was hardly able cover seemed ready slide off any moment. His many legs, pitifully thin compared size rest him, waved about helplessly as looked. \\x93What\\x92s happened me?\\x94 thought. It wasn\\x92t dream. room, proper human room although too small, peacefully between its four familiar walls. A collection textile samples spread out table\\x97Samsa travelling salesman\\x97and above there hung picture that had cut an illustrated magazine housed nice, gilded frame. showed lady fitted fur hat boa who sat upright, raising heavy muff covered whole her lower arm towards viewer. then turned look window dull weather. Drops rain be heard hitting pane, which made him feel quite sad. \\x93How sleep bit longer forget all nonsense\\x94, thought, but something unable do because used sleeping right, present state couldn\\x92t get position. However hard threw onto always rolled back was. must tried hundred times, shut eyes so wouldn\\x92t floundering only stopped began mild, pain never felt before. \\x93Oh, God\\x94, \\x93what strenuous career I\\x92ve chosen! Travelling day out. Doing business like takes much more effort than doing your own home, top there\\x92s curse travelling, worries making train connections, bad irregular food, contact different people time can know become friendly them. go Hell!\\x94 slight itch up belly; pushed slowly headboard lift better; was, saw lots white spots didn\\x92t what make of; place one legs drew quickly soon touched overcome cold shudder. slid former \\x93Getting early time\\x94, \\x93it makes stupid. You\\x92ve got enough sleep. Other salesmen live life luxury. For instance, whenever guest house during morning contract, these gentlemen still sitting eating their breakfasts. ought just try my boss; I\\x92d kicked spot. But knows, maybe would best thing me. parents think given notice long ago, gone boss told think, tell everything would, let feel. He\\x92d fall right desk! And it\\x92s funny sort desk, talking down subordinates there, especially close hearing. Well, some hope; once money together pay parents\\x92 debt him\\x97another five six years suppose\\x97that\\x92s definitely I\\x92ll do. That\\x92s big change. First though, up, leaves five.\\x94 looked over alarm clock, ticking chest drawers. \\x93God Heaven!\\x94 half past hands were quietly moving forwards, even later past, quarter seven. Had clock rung? been set o\\x92clock should been; certainly rung. Yes, possible through furniture-rattling noise? True, slept peacefully, probably deeply that. What now? next went seven; catch rush mad packed, did particularly fresh lively. avoid boss\\x92s anger office assistant go, put report Gregor\\x92s being ago. man, spineless, understanding. reported sick? extremely strained suspicious service yet ill. come round doctor medical insurance company, accuse having lazy son, accept doctor\\x92s recommendation claim believed no-one ever ill workshy. what\\x92s more, entirely wrong case? fact, apart excessive sleepiness after long, completely well hungrier usual. hurriedly thinking through, decide bed, struck There cautious knock door near head. \\x93Gregor\\x94, somebody called\\x97it mother\\x97\\x93it\\x92s Didn\\x92t want somewhere?\\x94 That gentle voice! shocked voice answering, recognised As deep inside painful uncontrollable squeaking mixed words first echo them unclear, leaving hearer unsure whether properly not. wanted full answer explain everything, circumstances contented saying: \\x93Yes, mother, yes, thank-you, I\\x92m getting now.\\x94 change noticed outside wooden door, mother satisfied explanation shuffled away. short conversation members family aware Gregor, against expectations father came knocking side doors, gently, fist. \\x93Gregor, Gregor\\x94, called, \\x93what\\x92s wrong?\\x94 while called again warning deepness voice: \\x93Gregor! Gregor!\\x94 At sister plaintively: \\x93Gregor? Aren\\x92t well? Do need anything?\\x94 answered both sides: \\x93I\\x92m ready, now\\x94, remove strangeness enunciating very carefully putting pauses each, individual word. breakfast, whispered: open beg you.\\x94 however, thought opening instead congratulated habit, acquired locking doors night home. peace without disturbed, dressed, breakfast. Only consider next, bring thoughts sensible conclusions lying bed. remembered often perhaps caused awkwardly, pure imagination wondered how imaginings resolve themselves today. slightest doubt nothing sign serious cold, occupational hazard salesmen. simple matter throw covers; blow they fell themselves. became difficult that, exceptionally broad. arms push up; those continuously directions, moreover control. bend them, stretch itself out; finally managed leg, others free move painfully. \\x93This can\\x92t done bed\\x94, said himself, \\x93so don\\x92t keep trying it\\x94. part body seen part, imagine like; move; slowly; finally, frenzy, carelessly shoved forwards force gather, chose direction, hit bedpost, learned burning might well, present, sensitive. So first, turning side. easily, despite breadth weight, bulk eventually followed direction last air occurred miracle injured, afraid carry pushing forward same way. now price; better stay lose consciousness. took earlier, sighing, watching struggled each harder before, possible, way bringing order chaos. whatever sacrifice. time, remind calm consideration rushing desperate conclusions. times direct clearly could, unfortunately, narrow street enveloped fog view confidence cheer offer him. \\x93Seven o\\x92clock, already\\x94, again, \\x93seven this.\\x94 longer, breathing lightly expected total stillness things real natural state. himself: \\x93Before strikes seven work ask me o\\x92clock.\\x94 task swinging entire length time. succeeded falling kept raised injuring it. hard, happen carpet. main concern loud noise bound make, raise alarm. risked. When already sticking bed\\x97the new method game effort, rock forth\\x97it help Two strong people\\x97he maid mind\\x97would enough; dome peel load patient careful swang floor, where, hopefully, find use. Should really call fact locked? Despite difficulty in, suppress smile After moved far across balance rocked hard. ten final decision soon. Then ring flat. \\x93That\\x92ll someone work\\x94, froze still, lively danced around. moment remained quiet. \\x93They\\x92re door\\x94, caught nonsensical hope. course, maid\\x92s firm steps opened needed hear visitor\\x92s greeting knew was\\x97the chief clerk himself. Why condemned company immediately highly shortcoming? Were employees, every louts, faithful devoted pangs conscience spend least couple hours business? Was trainees enquiries\\x97assuming enquiries necessary\\x97did show whole, innocent trusted wisdom investigate it? upset decision, thump, noise. softened carpet, also elastic sound muffled noticeable. held enough, fell; annoyed pain, rubbed \\x93Something\\x92s fallen there\\x94, left. today too; concede possible. gruff reply question, clerk\\x92s footsteps polished boots adjoining room. From whispered know: here.\\x94 know\\x94, himself; daring left, \\x93the has wants why leave train. We say anyway, speak personally. please door. sure he\\x92ll good forgive untidiness room.\\x94 \\x93Good Mr. Samsa\\x94. \\x93He isn\\x92t well\\x94, clerk, continued believe else missed train! lad thinks business. nearly cross goes evenings; he\\x92s town week stayed home evening. sits us kitchen reads paper studies timetables. idea relaxation working fretsaw. He\\x92s frame, two three evenings, you\\x92ll amazed nice is; hanging room; opens Anyway, glad you\\x92re here; we ourselves; stubborn; is, isn\\x92t.\\x94 \\x93I\\x92ll moment\\x94, thoughtfully, miss word conversation. \\x93Well explaining Mrs. Samsa\\x94, \\x93I hope serious. hand, commerce unwell then, fortunately unfortunately like, simply considerations.\\x94 \\x93Can then?\\x94, asked impatiently, again. \\x93No\\x94, Gregor. In silence; left cry. join others? She begun dressed. she crying? danger losing job pursue demands before? worry yet. intention abandoning family. condition seriously in. minor discourtesy, suitable excuse easily on, sacked disturbing crying. happening, worried, behaviour. voice, \\x93Mr. wrong? barricade yourself yes answer, causing unnecessary fail\\x97and mention way\\x97you fail duties unheard of. speaking here behalf employer, request clear immediate explanation. am astonished, astonished. person, suddenly seem showing peculiar whims. employer suggest reason failure appear, true\\x97it entrusted you\\x97but giving honour incomprehensible stubbornness wish whatsoever intercede behalf. nor position secure. originally intended private, since cause waste learn Your turnover unsatisfactory late; grant year business, recognise that; all, Samsa, cannot allow be.\\x94 \\x93But Sir\\x94, beside forgetting excitement, immediately, unwell, attack dizziness, haven\\x92t up. now. now, though. Just Be patient! It\\x92s easy alright shocking, person! night, me, small symptom already. They work! illness staying Please, suffer! There\\x92s basis accusations making; nobody\\x92s things. Maybe read latest contracts sent eight train, few strength. wait, sir; you, recommend him!\\x94 gushed words, knowing saying, drawers\\x97this done, practise bed\\x97where upright. clerk; insistent, curious sight responsibility rest. If, calmly upset, hurried station o\\x92clock. climb smooth drawers gave swing stood upright; attention Now nearby chair tightly edges legs. By calmed down, quiet listen saying. \\x93Did understand that?\\x94 parents, \\x93surely fools us\\x94. God!\\x94 tears, \\x93he we\\x92re suffer. Grete! Grete!\\x94 cried. \\x93Mother?\\x94 communicated \\x93You\\x92ll straight Quick, doctor. Did spoke now?\\x94 \\x93That animal\\x94, calmness contrast mother\\x92s screams. \\x93Anna! Anna!\\x94 entrance hall, clapping hands, \\x93get locksmith here, now!\\x94 girls, skirts swishing, ran wrenching front flat went. How dressed quickly? banging again; open; homes awful happened. contrast, calmer. clearer before\\x97perhaps ears sound. realised, help. response situation confident wise, better. drawn among people, great surprising achievements\\x97although distinguish other. Whatever crucial, so, coughed little, taking care loudly coughs judge Meanwhile, Perhaps table whispering pressed listening. chair. Once holding upright adhesive tips rested recover involved key lock mouth. seemed, teeth\\x97how he, grasp key?\\x97but lack teeth jaw; jaw, start turning, ignoring kind damage fluid mouth, flowed dripped floor. \\x93Listen\\x94, \\x93he\\x92s key.\\x94 greatly encouraged this; calling too: cried, \\x93keep hold lock!\\x94 excitedly following efforts, strength, paying around weight needed. snapped break concentration, regained breath \\x93So, all\\x94. handle completely. Because way, wide seen. turn double entering occupied movement, anything else, exclaim \\x93Oh!\\x94, sounded soughing wind. him\\x97he nearest door\\x97his hand mouth retreating driven steady invisible force. hair dishevelled father. unfolded arms, sank floor disappeared breast. hostile, clenched fists wanting uncertainly living wept powerful shook. leant bolted place. seen, along peered others. Meanwhile lighter; endless, grey-black building street\\x97which hospital\\x97could austere regular line windows piercing fa√ßade; falling, throwing large, droplets ground washing breakfast table; because, father, important meal several reading number newspapers. On wall exactly opposite photograph lieutenant army, sword carefree face forth respect uniform bearing. hall landing stairs below. \\x93Now, then\\x94, calm, pack off. Will leave? see\\x94, \\x93that stubborn job; commercial traveller arduous earn living. going, office? Yes? accurately, then? temporarily work, that\\x92s remember achieved removed, diligence concentration. You\\x92re our sister, trapped situation, already, take sides office. nobody likes travellers. enormous wage soft prejudice particular sir, overview staff, confidence, himself\\x97it\\x92s businessman mistakes employees harshly should. travellers office, victim gossip chance groundless complaints, impossible defend thing, usually arrive exhausted trip, harmful effects going away, partly right!\\x94 started speak, and, protruding lips, stared trembling shoulders speaking, steadily gradually, secret prohibition reached sudden foot rushed panic. stretched stairway supernatural waiting save realised question mood extreme danger. well; years, convinced provide life, besides, lost future. won over; future depended it! here! clever; tears back. lover women, surely persuade him; talk considering state, speech not\\x97or not\\x97be understood, door; opening; reach who, ridiculously, banister hands; scream sought onto, landed numerous Hardly than, day, body; solid them; pleasure, go; believing sorrows end. urge swayed crouched engrossed herself, jumped outstretched fingers shouting: \\x93Help, pity\\x92s sake, Help!\\x94 suggested better, unthinking hurrying backwards not; forgotten behind it; doing; seeming coffee pot knocked gush pouring \\x93Mother, mother\\x94, looking her. moment, snapping jaws flow coffee. screaming anew, fled spare now; stairs; chin banister, run reaching something, leapt disappeared; shouts resounding staircase. flight panic well. Until relatively self controlled, running impeding seized stick (the chair, overcoat), picked large newspaper drive stamping appeals help, however humbly merely stamped harder. Across chilly weather, pulled window, face. draught flew stairway, curtains newspapers fluttered blown Nothing stop drove hissing noises wild man. practice slowly. allowed impatient, threat lethal father\\x92s Eventually, choice saw, disgust, incapable line; began, frequent anxious glances round. slowly, intentions hinder tip directions distance turn. unbearable hissing! confused. finished round, listening hissing, mistake come. pleased doorway, narrow, broad further difficulty. mood, obviously occur space through. fixed Nor preparation doorway. did, ever, way; pleasant experience, doorway regard happen. itself, angle flank scraped painfully vile flecks stuck fast quivering ground. hefty shove released flying, heavily bleeding, slammed stick, II until dark evening awoke coma-like woken afterwards anyway hadn\\x92t fully rested. impression leading light electric lamps shone palely ceiling tops furniture, below, dark. feeling clumsily antennae\\x97of beginning value\\x97in happening there. one, scar, limped badly rows injured events morning\\x97it been\\x97and dragged lifelessly. actually smell eat. dish filled sweetened milk pieces bread floating laughed, dipped milk, covering disappointment; tender eat food\\x97he worked snuffling whole\\x97but taste nice. Milk normally favourite drink, turned, will, crawled centre Through crack gas lit paper, sometimes heard. write reading, habit recent times. too, though \\x93What lead\\x94, gazing darkness, pride such parents. wealth comfort frightening end? much, about, crawling evening, closed same; enter waited resolved either timorous visitor was; vain. previous locked everyone unlocked came, keys sides. late gaslight out, awake distinctly tip-toe. morning; plenty undisturbed re-arrange life. reason, tall, empty forced remain uneasy years. shame, couch. head, nonetheless ease regret underneath. spent Some passed sleep, frequently hunger, vague hopes which, led conclusion: patience greatest bear unpleasantness condition, impose opportunity test strength decisions, ended, anxiously couch\\x97he somewhere, God\\x92s flown away\\x97she control herself outside. behaviour, tip-toe stranger. forward, edge couch, watched Would realise hunger food suitable? rather hungry draw terrible sister\\x92s feet However, drops splashed surprise. up\\x97using rag, bare hands\\x97and carried place, imagining wildest possibilities, guessed goodness, bring. taste, brought selection things, old newspaper. old, half-rotten vegetables; bones meal, sauce hard; raisins almonds; cheese declared inedible days before; dry roll butter salt. poured water dish, permanently aside use, placed Then, feelings, her, comfortable liked. whirred, What\\x92s injuries healed moving. month earlier finger knife, hurt yesterday. \\x93Am less sensitive be, sucking greedily compellingly, attracted foods Quickly another, watering consumed cheese, vegetables sauce; foods, stand smell. Long lethargic withdraw. startled, asleep, self-control rounded breathe space. Half suffocating, bulging unselfconsciously broom swept left-overs, mixing more. dropped bin, lid, couch received second eaten midday send errand. starve either, experience feeding distress indeed suffering enough. nobody, content sighs saints later, everything\\x97there becoming situation\\x97that comment, comment construed friendly. \\x93He\\x92s enjoyed dinner today\\x94, diligently cleared frequent, say, sadly, \\x93now everything\\x92s again\\x94. Although news directly rooms, scurry appropriate press seldom conversation, secret. days, mealtime meals subject home\\x97nobody empty. knees begged delay. within hour, tearfully thanking dismissal service. swore emphatically happened, cooking; bother ate much. unsuccessfully another eat, receive \\x93no thanks, enough\\x94 similar. No-one drank either. beer, hoping fetch herself. add, selfish, housekeeper big, said. Even end, explained finances prospects were. receipt document cash box saved collapsed earlier. complicated taken item wanted. incarcerated different, anyway. Their misfortune reduced despair, arrange fiery vigour junior salesman representative overnight, ways. converted success benefit astonished delighted splendour, earned costs family, gratitude warm affection return. Unlike fond music gifted expressive violinist, plan conservatory expense During periods town, mentioned lovely dream realised. talk, decided planned grand announcement Christmas day. totally pointless mind tired continue listening, wearily pull start, silent. while, interrupted repeated matters explanations learned, misfortunes available days. lot, meantime interest accumulated. Besides month, keeping accumulating. Behind nodded enthusiasm pleasure unexpected thrift caution. surplus reduce boss, freed closer, money, enable interest; maintain for, perhaps, emergencies; earned. healthy lacking confidence. working\\x97the holiday strain success\\x97he lot slow clumsy. elderly money? suffered asthma struggling sofa window. child seventeen, till enviable, consisting wearing clothes, late, helping joining modest pleasures playing violin. Whenever cool, leather hot shame regret. lie wink scratching Or climbing sill propped leaning stare sense freedom this, experienced, distinct near; ever-present hospital street, known lived Charlottenstrasse, middle city, barren grey sky earth mingled inseparably. observant twice exact tidied inner pane on. thank easier pain. naturally, pretend burdensome unpleasant entered No sooner precaution suffer suffocating. while. shivering liked ordeal, closed. transformation appearance, usual staring motionless, horrible. coming surprise stranger threatened bite hide wait appearance flee protruded sight, carrying bedsheet arranged bent down. sheet necessary glimpsed arrangement. fourteen appreciated girl somewhat useless looked, eaten, behaved whether, improvement visit persuaded listened closely approved fully. Later, force, out: \\x93Let unfortunate son! Can\\x92t him?\\x94, week, perhaps; courage, adult\\x92s appreciation Out square meters crawl entertain walls ceiling. ceiling; floor; freely; relaxed happy, letting crash. damage. Very entertaining himself\\x97he had, traces about\\x97and removing furniture desk. Now, herself; dare father; sixteen bravely cook helped unless important; choose approached express joy, First, alright; enter. folds thrown chance. refrained, spying sheet; \\x93You seen\\x94, hand. pair feeble women heaving heaviest warnings lasted labouring fifteen minutes opposite; saddened heart; he\\x92d abandoned quietly, (whose whereabouts know) tone added \\x93and won\\x92t we\\x92ve cope himself? it\\x92d comes unchanged easier\\x94. Hearing communication, monotonous months, confused\\x97he emptied transform cave, inherited? unimpeded human. forgetting, shaken removed; stay; influence condition; mindlessly loss advantage. agree; idea, spokesman concerned meant advice sufficient insist all-important childish perversity, acquired, insist; whereas see, all. Girls age, enthusiastic can. tempted Grete shocking dominated refused dissuade had. to, writing desk stay. drawers, groaning, poked considerate but, chest, pulling without, inch. ill, end startlement, prevent little. attract attention. Grete. assure unusual admit fro, calls other, scraping assailed With longer. emptying dear containing fretsaw tools; worn homework trainee, high school, infant school\\x97he women\\x92s good. stepped So, catching breath, sallied changed wall\\x97which denuded it\\x97of copious fur. glass, firmly belly. least, no-one. watch soon; shall Her met wall. said, albeit tremor \\x93Come let\\x92s while?\\x94 mind, somewhere safe chase unyielding picture. jump Grete\\x92s side, patch flowers wallpaper, screamed: \\x93Oh God, oh Arms outstretched, immobile. \\x93Gregor!\\x94 shouted glowering shaking spoken transformation. smelling salts faint; too\\x97he glass force; advise days; nothing; various bottles, startled round; bottle broke; splinter face, caustic medicine delaying bottles mother; foot. death; wait; oppressed anxiety self-reproach, walls, ceiling, confusion spin table. numb immobile, quiet, sign. maid, arrived happened?\\x94 words; subdued openly chest: \\x93Mother\\x92s fainted, she\\x92s out.\\x94 \\x93Just expected\\x94, \\x93just listen, mean responsible act violence. delay, disappear. subtleties \\x93Ah!\\x94, sounding angry imagined neglected changed, father? man laying entombed trips, armchair nightgown walk Sunday public wrapped overcoat labour walking sake; invariably gather companions standing smart blue gold buttons, banking institute; high, collar coat double-chin emerged; bushy eyebrows, piercing, alert; unkempt combed scalp. cap, monogram from, probably, bank, arc sofa, trouser pockets, bottom coat, determination, walked unusually high. soles boots, wasted that\\x97he strict stopped, scurried moved, slightly. decisive largely feared provoking step countless movements. noticeably lungs reliable. lurched efforts muster saving running; forgot although, concealed carved notches protrusions\\x97then, tossed, apple; shock; point bombard pockets fruit bowl sideboard aim, apple another. These red apples motors. An glanced harm. Another squarely lodged back; drag surprising, incredible changing position; nailed spot senses confusion. open, screaming, blouse (as clothes fainted breathe), unfastened sliding ground, stumbling uniting totally\\x97now ability anything\\x97her begging III dared flesh, visible reminder injury. current sad revolting form, member treated enemy. contrary, duty swallow revulsion patient, patient. injuries, mobility\\x97probably permanently. ancient invalid room\\x97crawling question\\x97but deterioration (in opinion) darkness conversation\\x97with everyone\\x92s permission, thus differently conversations ones longing damp hotel All nowadays. Soon dinner, chair; quiet; lamp, sew fancy underwear fashion shop; sales job, shorthand French evenings Sometimes wake \\x93you\\x92re sewing today!\\x94, dozing\\x97and exchange grin. stubbornness, home; unused peg slumber serve expecting superior here. with, result shabbier stains buttons shiny, uncomfortable peaceful. ten, gently work. obstinate table, regularly asleep importune reproaches hour refusing tug sleeve, whisper endearments ear, effect sink deeper abruptly eyes, say: life! age!\\x94 supported needle pen Who, overworked absolutely necessary? household budget smaller; dismissed; enormous, thick-boned charwoman flapped work; amount did. price hoped items jewellery belonging sold, functions celebrations. loudest complaint circumstances, imaginable transferring address. reasons move, transport crate holes unlike experienced related to. expects poor bank sacrificed strangers, behest customers, injury new. sit together, cheek cheek; \\x93Close Grete\\x94, mingle, dry-eyed family\\x92s affairs, opened; appear thoughts, apprentices, stupid teaboy, friends businesses, chambermaids provincial hotel, memory appeared cashier shop whom slow,\\x97all strangers forgotten, inaccessible, disappeared. rage shown, wanted, plans pantry entitled hungry. midday, sweep broom, indifferent or\\x97more not\\x97had untouched. quicker Smears dirt balls dust filth. worst places reproach weeks touchy understood\\x97cleaning alone. thoroughly clean bucketfuls it\\x97although dampness bitter punished aggrieved, mothers imploring broke convulsive tears. helpless; they, agitated; accused cleaning sister; screamed anger, bedroom; quaking thumped fists; hissed closing neglected. widow, robust bone structure withstand hardest repelled curiosity, surprise, chasing fro amazement crossed failed briefly considered friendly, \\x93come dung-beetle!\\x94, \\x93look dung-beetle there!\\x94 responded opened. disturb windowpanes, indicating spring coming, resentful toward infirm, attack. Instead afraid, chairs intending \\x93Aren\\x92t corner. eating. prepared play not, spit eating, changes rooms rented gentlemen. earnest gentlemen\\x97all beards, peering day\\x97were insistent things\\x92 tidy. establishment, kitchen. Unnecessary clutter tolerate, dirty. furnishings equipment superfluous discard. dustbins too. hurry, chuck He, fortunately, object woman likely opportunity, junk else. enjoy death, immobile afterwards. everyone, lain darkest formerly, serviettes knives forks. meat piled potatoes. steaming, dishes gentleman middle, count authority two, piece wishing establish sufficiently cooked satisfaction, anxiously, smiled. Nonetheless, kitchen, bowed cap mumbled beards. alone, perfect silence. remarkable chewing heard, perform toothless be. \\x93I\\x92d something\\x94, \\x93but they\\x92re feed am, dying!\\x94 Throughout violin played, produced newspaper, page others, smoking. attentive, hallway Someone \\x93Is gentlemen? away.\\x94 \\x93On contrary\\x94, gentleman, \\x93would young cosy comfortable?\\x94 we\\x92d love to\\x94, player waited. stand, begin playing; therefore exaggerated courtesy gentlemen, chairs; coat; offered seat sat\\x97leaving it\\x97out play; paid attention, movements hands. Drawn playing, Before, thoughtless hidden everywhere movement; threads, hairs, remains sides; wipe carpet shy immaculate preoccupied notes disturbed soon, withdrew heads sunk volume, observed anxiously. obvious beautiful disappointed, performance politeness disturbed. unnerving, blew smoke cigarettes upwards noses. Yet beautifully. lines melancholy expression. meet came. animal captivate so? shown unknown nourishment yearning for. determined skirt violin, would. lived, anyway; should, once, hiss attackers; will; ear conservatory, Christmas\\x97had already?\\x97if refuse hearing emotion, shoulder kiss neck, necklace collar. Samsa!\\x94, pointing, wasting forefinger forward. silent, smiled friends, driving been. attempted block body. annoyed, behaviour dawning realisation neighbour explanations, tugged beards despair interrupted. drop bow hang limply instrument lap laboriously pressure toward. Under pillows covers beds slipped obsessed owed tenants. urged until, thunder thereby halt. declare glancing gain repugnant conditions prevail family\\x94\\x97here decisively floor\\x97\\x93I contrary proceed action damages grounds action.\\x94 silent ahead something. indeed, joined words: \\x93And notice.\\x94 staggered seat, stretching nap uncontrolled nodding disappointment plan, weak move. \\x93Father, Mother\\x94, introduction, \\x93we this. monster brother, is: rid We\\x92ve humanly wrong.\\x94 \\x93She\\x92s right\\x94, cough dully, deranged expression eyes. forehead. definite ideas. played plates occasionally \\x93We it\\x94, coughing \\x93it\\x92ll death coming. tortured endure more.\\x94 wiped mechanical \\x93My child\\x94, sympathy understanding, do?\\x94 shrugged helplessness displacing certainty. \\x93If us\\x94, question; shook vigorously question. acceptance certainty impossible, \\x93then arrangement ...\\x94 \\x93It\\x92s go\\x94, \\x93that\\x92s Father. harmed ourselves long. Gregor? ago beings will. brother lives respect. persecuting us, tenants, streets. Father, look, look\\x94, screamed, starting again!\\x94 alarm, beyond comprehension, willing sacrifice excited protect anyone, sister. startling pain-wracked required deal repeatedly striking alarmed briefly. unhappy exhaustion; neck. \\x93Maybe they\\x92ll round\\x94, panting ahead. separated noticing concentrated word, cry, distract neck stiff, glance asleep. shut, locked. rush. sprung lightly, \\x93At last!\\x94. darkness. discovery spindly unnatural. comfortable. true aching, weaker disappear altogether. decayed inflamed area dust. emotion love. strongly peaceful rumination tower strike morning. completely, weakly nostrils. cleaner morning\\x97they\\x92d slamming hurry she\\x92d peace\\x97she brief special. purpose, martyr; attributed understanding tickle nuisance resistance wide, whistled yank bedroom shout bedrooms: \\x92ave dead, stone dead!\\x94 marriage shock blanket shoulders, nightdress; in; paleness confirm \\x93Dead?\\x94, enquiringly, checked checking. \\x93That\\x92s said\\x94, replied cleaner, prove sending sideways movement complete \\x93Now \\x93let\\x92s thanks God that\\x94. example. Grete, corpse, said: in\\x94. dried flat, \\x93Grete, while\\x94, pained smile, wide. warmth March, breakfasts; about. \\x93Where breakfast?\\x94, irritably. lips quick men corpse well-worn coats. wife daughter crying little; arm. \\x93Leave Now!\\x94, mean?\\x94, disconcerted, sweetly. backs continually gleeful anticipation quarrel favour. companions, contents rearranging positions. \\x93Alright, we\\x92ll humility permission decision. strides hallway; rubbing friend fear connection leader. hats sticks holder, premises. landing; mistrust men\\x92s leaned progress steps. corner reappear moments later; went, butcher\\x92s boy, proud posture tray nearer were, relieved, walk; wrote letters excusal, employers, contractor principal. writing, irritation. \\x93Well?\\x94, Samsa. tremendous report, vertical ostrich feather hat, source irritation directions. \\x93Yes\\x94, answered, laugh \\x93well needn\\x92t sorted intent continuing writing; describing detail prevented telling peeved, \\x93Cheerio everyone\\x94, sharply terribly \\x93Tonight gets sacked\\x94, destroyed gained. twisted then. Let\\x92s stuff, we. Come attention\\x94. kissed hugged letters. tram town. tram, sunshine, Leant comfortably seats, discussed closer examination bad\\x97until jobs promise being, house; smaller cheaper chosen location practical. livelier. cheeks pale, talking, struck, simultaneously, blossoming built lady. quieter. other\\x92s agreed And, confirmation dreams intentions, destination END Updated editions replace one\\x97the renamed. Creating works print protected U.S. law means owns works, Foundation (and you!) distribute royalties. Special rules, General Terms Use license, apply copying distributing Gutenberg\\x99 electronic GUTENBERG\\x99 concept trademark. registered trademark, charge eBook, except trademark including royalties copies complying license easy. purpose creation derivative reports, performances research. eBooks modified printed away\\x97you practically ANYTHING law. Redistribution redistribution. START: FULL LICENSE PLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE WORK To mission promoting distribution (or associated phrase \\x93Project Gutenberg\\x94), agree comply Full file www.gutenberg.org/license. Section 1. Redistributing 1.A. indicate read, understand, intellectual property (trademark/copyright) agreement. abide agreement, cease return destroy possession. fee obtaining access obtain refund person entity paragraph 1.E.8. 1.B. Gutenberg\\x94 See 1.C agreement preserve works. 1.E 1.C. Literary Archive (\\x93the Foundation\\x94 PGLAF), compilation Nearly domain States. unprotected copying, distributing, performing, displaying creating based references removed. Of support freely sharing compliance name format attached share remainder world, holder. Information owner imposed holder 1.D. govern Copyright countries constant addition downloading, displaying, representations concerning status 1.E. Unless removed Gutenberg: 1.E.1. sentence, active links prominently (any appears, associated) accessed, displayed, performed, viewed, copied distributed: 1.E.2. derived texts (does contain posted holder), distributed fees charges. redistributing providing appearing requirements paragraphs 1.E.1 1.E.7 1.E.8 1.E.9. 1.E.3. additional Additional linked 1.E.4. unlink detach files Gutenberg\\x99. 1.E.5. copy, display, perform, redistribute sentence License. 1.E.6. convert binary, compressed, marked nonproprietary proprietary processing hypertext form. \\x93Plain Vanilla ASCII\\x94 official version website (www.gutenberg.org), must, cost, user, exporting upon request, original Any alternate include specified 1.E.7. viewing, reasonable provided that: \\x95 royalty 20% gross profits derive calculated calculate applicable taxes. donate Foundation. Royalty payments 60 date prepare legally prepare) periodic tax returns. address 4, \\x93Information donations Foundation.\\x94 user notifies e-mail) 30 s/he does require possessed physical medium discontinue provide, accordance 1.F.3, replacement defect discovered 90 group Foundation, manager Contact 3 1.F. 1.F.1. volunteers expend considerable identify, research transcribe proofread collection. stored, \\x93Defects,\\x94 as, limited incomplete, inaccurate corrupt data, transcription errors, infringement, defective damaged disk medium, computer virus, codes equipment. 1.F.2. LIMITED WARRANTY, DISCLAIMER DAMAGES - Except \\x93Right Replacement Refund\\x94 described party disclaim liability damages, expenses, legal fees. AGREE THAT HAVE NO REMEDIES FOR NEGLIGENCE, STRICT LIABILITY, BREACH WARRANTY CONTRACT EXCEPT THOSE PROVIDED IN PARAGRAPH 1.F.3. FOUNDATION, TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER AGREEMENT WILL NOT BE LIABLE TO ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE INCIDENTAL EVEN IF GIVE NOTICE POSSIBILITY SUCH DAMAGE. RIGHT REPLACEMENT REFUND discover receiving (if any) written from. elect lieu refund. electronically, electronically defective, demand opportunities fix problem. 1.F.4. \\x91AS-IS\\x92, WITH OTHER WARRANTIES KIND, EXPRESS IMPLIED, INCLUDING BUT MERCHANTABILITY FITNESS PURPOSE. 1.F.5. states disclaimers certain implied warranties exclusion limitation types damages. disclaimer violates interpreted maximum permitted invalidity unenforceability provision void remaining provisions. 1.F.6. INDEMNITY indemnify owner, agent employee production, promotion harmless liability, fees, arise indirectly occur: (a) (b) alteration, modification, additions deletions (c) Defect cause. 2. Mission synonymous formats readable widest variety computers obsolete, middle-aged computers. exists hundreds walks Volunteers financial assistance critical Gutenberg\\x99\\x92s goals ensuring generations 2001, created secure permanent generations. Sections 4 information 3. non-profit 501(c)(3) educational corporation organized Mississippi granted exempt Internal Revenue Service. Foundation\\x92s EIN federal identification 64-6221541. Contributions deductible extent state\\x92s laws. 809 North 1500 West, Salt Lake City, UT 84116, (801) 596-1887. Email www.gutenberg.org/contact 4. Donations depends survive widespread increasing licensed machine-readable form accessible array outdated Many ($1 $5,000) maintaining IRS. committed regulating charities charitable 50 Compliance paperwork requirements. solicit locations compliance. SEND DONATIONS determine www.gutenberg.org/donate. While contributions solicitation requirements, accepting unsolicited donors approach offers donate. International gratefully accepted, statements treatment alone swamp staff. web pages donation methods addresses. accepted ways checks, credit card donations. donate, visit: 5. About Professor Michael S. Hart originator library shared anyone. forty loose network volunteer support. editions, confirmed included. Thus, necessarily edition. PG search facility: includes Gutenberg\\x99, produce eBooks, subscribe email newsletter eBooks.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c38f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c71e7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer, open('tokenizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1927635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dba4d2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57, 329, 5, 17, 30, 330, 8, 17, 58, 31]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfb3a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e4ce31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3246"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "783dabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for i in range(1, len(sequence_data)):\n",
    "    words = sequence_data[i-1:i+1]\n",
    "    sequences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9105d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4773"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cb9d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93bde057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 860, 3245])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8757761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =[]\n",
    "y = []\n",
    "for i in sequences:\n",
    "    x.append(i[0])\n",
    "    y.append(i[1])\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fbf2c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes = vocab_size)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8c025f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24424ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_size, 10, input_length = 1))\n",
    "model.add(LSTM(units=1024, return_sequences=True))\n",
    "model.add(LSTM(units=1024))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "525fe9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 10)             32460     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 1024)           4239360   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1024)              8392704   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3246)              3327150   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,041,274\n",
      "Trainable params: 17,041,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41c7b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "checkpoints = ModelCheckpoint('model_nwp.h5', monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
    "reduces = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr = 0.0001, verbose=1)\n",
    "logdir = 'lognw'\n",
    "tensorboard_vis = TensorBoard(log_dir= logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4b55a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss= 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1602682f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 8.0974\n",
      "Epoch 1: loss improved from inf to 8.09738, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 92s 548ms/step - loss: 8.0974 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 8.0619\n",
      "Epoch 2: loss improved from 8.09738 to 8.06194, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 68s 456ms/step - loss: 8.0619 - lr: 0.0010\n",
      "Epoch 3/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 7.9348\n",
      "Epoch 3: loss improved from 8.06194 to 7.93485, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 447ms/step - loss: 7.9348 - lr: 0.0010\n",
      "Epoch 4/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 7.5881\n",
      "Epoch 4: loss improved from 7.93485 to 7.58805, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 444ms/step - loss: 7.5881 - lr: 0.0010\n",
      "Epoch 5/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 7.1948\n",
      "Epoch 5: loss improved from 7.58805 to 7.19480, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 69s 457ms/step - loss: 7.1948 - lr: 0.0010\n",
      "Epoch 6/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.8544\n",
      "Epoch 6: loss improved from 7.19480 to 6.85440, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 71s 472ms/step - loss: 6.8544 - lr: 0.0010\n",
      "Epoch 7/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.5345\n",
      "Epoch 7: loss improved from 6.85440 to 6.53449, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 69s 463ms/step - loss: 6.5345 - lr: 0.0010\n",
      "Epoch 8/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.1802\n",
      "Epoch 8: loss improved from 6.53449 to 6.18016, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 78s 521ms/step - loss: 6.1802 - lr: 0.0010\n",
      "Epoch 9/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 5.7955\n",
      "Epoch 9: loss improved from 6.18016 to 5.79546, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 75s 499ms/step - loss: 5.7955 - lr: 0.0010\n",
      "Epoch 10/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 5.4528\n",
      "Epoch 10: loss improved from 5.79546 to 5.45279, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 80s 531ms/step - loss: 5.4528 - lr: 0.0010\n",
      "Epoch 11/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 5.1397\n",
      "Epoch 11: loss improved from 5.45279 to 5.13975, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 83s 555ms/step - loss: 5.1397 - lr: 0.0010\n",
      "Epoch 12/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.8556\n",
      "Epoch 12: loss improved from 5.13975 to 4.85556, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 66s 442ms/step - loss: 4.8556 - lr: 0.0010\n",
      "Epoch 13/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.6276\n",
      "Epoch 13: loss improved from 4.85556 to 4.62761, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 68s 453ms/step - loss: 4.6276 - lr: 0.0010\n",
      "Epoch 14/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.4181\n",
      "Epoch 14: loss improved from 4.62761 to 4.41814, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 69s 458ms/step - loss: 4.4181 - lr: 0.0010\n",
      "Epoch 15/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.1738\n",
      "Epoch 15: loss improved from 4.41814 to 4.17378, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 65s 436ms/step - loss: 4.1738 - lr: 0.0010\n",
      "Epoch 16/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.9967\n",
      "Epoch 16: loss improved from 4.17378 to 3.99670, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 74s 495ms/step - loss: 3.9967 - lr: 0.0010\n",
      "Epoch 17/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.8291\n",
      "Epoch 17: loss improved from 3.99670 to 3.82906, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 83s 552ms/step - loss: 3.8291 - lr: 0.0010\n",
      "Epoch 18/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.6453\n",
      "Epoch 18: loss improved from 3.82906 to 3.64526, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 85s 569ms/step - loss: 3.6453 - lr: 0.0010\n",
      "Epoch 19/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.4882\n",
      "Epoch 19: loss improved from 3.64526 to 3.48823, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 73s 484ms/step - loss: 3.4882 - lr: 0.0010\n",
      "Epoch 20/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.3764\n",
      "Epoch 20: loss improved from 3.48823 to 3.37642, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 70s 469ms/step - loss: 3.3764 - lr: 0.0010\n",
      "Epoch 21/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.2237\n",
      "Epoch 21: loss improved from 3.37642 to 3.22368, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 68s 457ms/step - loss: 3.2237 - lr: 0.0010\n",
      "Epoch 22/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.1249\n",
      "Epoch 22: loss improved from 3.22368 to 3.12485, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 78s 520ms/step - loss: 3.1249 - lr: 0.0010\n",
      "Epoch 23/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.0349\n",
      "Epoch 23: loss improved from 3.12485 to 3.03494, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 85s 564ms/step - loss: 3.0349 - lr: 0.0010\n",
      "Epoch 24/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.9383\n",
      "Epoch 24: loss improved from 3.03494 to 2.93829, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 77s 513ms/step - loss: 2.9383 - lr: 0.0010\n",
      "Epoch 25/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.8253\n",
      "Epoch 25: loss improved from 2.93829 to 2.82529, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 76s 506ms/step - loss: 2.8253 - lr: 0.0010\n",
      "Epoch 26/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.7393\n",
      "Epoch 26: loss improved from 2.82529 to 2.73934, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 90s 603ms/step - loss: 2.7393 - lr: 0.0010\n",
      "Epoch 27/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.6383\n",
      "Epoch 27: loss improved from 2.73934 to 2.63826, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 83s 551ms/step - loss: 2.6383 - lr: 0.0010\n",
      "Epoch 28/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.5305\n",
      "Epoch 28: loss improved from 2.63826 to 2.53054, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 82s 545ms/step - loss: 2.5305 - lr: 0.0010\n",
      "Epoch 29/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.4725\n",
      "Epoch 29: loss improved from 2.53054 to 2.47255, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 70s 468ms/step - loss: 2.4725 - lr: 0.0010\n",
      "Epoch 30/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.3866\n",
      "Epoch 30: loss improved from 2.47255 to 2.38656, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 97s 646ms/step - loss: 2.3866 - lr: 0.0010\n",
      "Epoch 31/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.3070\n",
      "Epoch 31: loss improved from 2.38656 to 2.30703, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 87s 579ms/step - loss: 2.3070 - lr: 0.0010\n",
      "Epoch 32/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.2105\n",
      "Epoch 32: loss improved from 2.30703 to 2.21051, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 92s 614ms/step - loss: 2.2105 - lr: 0.0010\n",
      "Epoch 33/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.1588\n",
      "Epoch 33: loss improved from 2.21051 to 2.15884, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 81s 540ms/step - loss: 2.1588 - lr: 0.0010\n",
      "Epoch 34/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.0899\n",
      "Epoch 34: loss improved from 2.15884 to 2.08987, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 2.0899 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.0208\n",
      "Epoch 35: loss improved from 2.08987 to 2.02084, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 84s 561ms/step - loss: 2.0208 - lr: 0.0010\n",
      "Epoch 36/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.9753\n",
      "Epoch 36: loss improved from 2.02084 to 1.97530, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 91s 610ms/step - loss: 1.9753 - lr: 0.0010\n",
      "Epoch 37/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.9080\n",
      "Epoch 37: loss improved from 1.97530 to 1.90802, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 1.9080 - lr: 0.0010\n",
      "Epoch 38/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.8470\n",
      "Epoch 38: loss improved from 1.90802 to 1.84705, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 79s 528ms/step - loss: 1.8470 - lr: 0.0010\n",
      "Epoch 39/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.8114\n",
      "Epoch 39: loss improved from 1.84705 to 1.81137, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 83s 555ms/step - loss: 1.8114 - lr: 0.0010\n",
      "Epoch 40/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.7647\n",
      "Epoch 40: loss improved from 1.81137 to 1.76467, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 84s 562ms/step - loss: 1.7647 - lr: 0.0010\n",
      "Epoch 41/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.7081\n",
      "Epoch 41: loss improved from 1.76467 to 1.70815, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 100s 670ms/step - loss: 1.7081 - lr: 0.0010\n",
      "Epoch 42/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.6626\n",
      "Epoch 42: loss improved from 1.70815 to 1.66261, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 70s 469ms/step - loss: 1.6626 - lr: 0.0010\n",
      "Epoch 43/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.6554\n",
      "Epoch 43: loss improved from 1.66261 to 1.65543, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 79s 529ms/step - loss: 1.6554 - lr: 0.0010\n",
      "Epoch 44/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.5955\n",
      "Epoch 44: loss improved from 1.65543 to 1.59553, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 73s 486ms/step - loss: 1.5955 - lr: 0.0010\n",
      "Epoch 45/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.5820\n",
      "Epoch 45: loss improved from 1.59553 to 1.58199, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 447ms/step - loss: 1.5820 - lr: 0.0010\n",
      "Epoch 46/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.5330\n",
      "Epoch 46: loss improved from 1.58199 to 1.53297, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 445ms/step - loss: 1.5330 - lr: 0.0010\n",
      "Epoch 47/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.4799\n",
      "Epoch 47: loss improved from 1.53297 to 1.47988, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 1197s 8s/step - loss: 1.4799 - lr: 0.0010\n",
      "Epoch 48/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.4590\n",
      "Epoch 48: loss improved from 1.47988 to 1.45904, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 91s 607ms/step - loss: 1.4590 - lr: 0.0010\n",
      "Epoch 49/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 49: loss improved from 1.45904 to 1.41726, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 101s 676ms/step - loss: 1.4173 - lr: 0.0010\n",
      "Epoch 50/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 50: loss improved from 1.41726 to 1.39837, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 93s 620ms/step - loss: 1.3984 - lr: 0.0010\n",
      "Epoch 51/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 51: loss did not improve from 1.39837\n",
      "150/150 [==============================] - 87s 582ms/step - loss: 1.4015 - lr: 0.0010\n",
      "Epoch 52/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3700\n",
      "Epoch 52: loss improved from 1.39837 to 1.37001, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 80s 535ms/step - loss: 1.3700 - lr: 0.0010\n",
      "Epoch 53/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3759\n",
      "Epoch 53: loss did not improve from 1.37001\n",
      "150/150 [==============================] - 89s 593ms/step - loss: 1.3759 - lr: 0.0010\n",
      "Epoch 54/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3399\n",
      "Epoch 54: loss improved from 1.37001 to 1.33993, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 93s 621ms/step - loss: 1.3399 - lr: 0.0010\n",
      "Epoch 55/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3116\n",
      "Epoch 55: loss improved from 1.33993 to 1.31163, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 90s 599ms/step - loss: 1.3116 - lr: 0.0010\n",
      "Epoch 56/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3004\n",
      "Epoch 56: loss improved from 1.31163 to 1.30043, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 79s 529ms/step - loss: 1.3004 - lr: 0.0010\n",
      "Epoch 57/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2774\n",
      "Epoch 57: loss improved from 1.30043 to 1.27741, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 77s 513ms/step - loss: 1.2774 - lr: 0.0010\n",
      "Epoch 58/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2436\n",
      "Epoch 58: loss improved from 1.27741 to 1.24355, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 448ms/step - loss: 1.2436 - lr: 0.0010\n",
      "Epoch 59/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2150\n",
      "Epoch 59: loss improved from 1.24355 to 1.21501, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 66s 442ms/step - loss: 1.2150 - lr: 0.0010\n",
      "Epoch 60/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1887\n",
      "Epoch 60: loss improved from 1.21501 to 1.18870, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 73s 485ms/step - loss: 1.1887 - lr: 0.0010\n",
      "Epoch 61/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1632\n",
      "Epoch 61: loss improved from 1.18870 to 1.16322, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 65s 434ms/step - loss: 1.1632 - lr: 0.0010\n",
      "Epoch 62/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1617\n",
      "Epoch 62: loss improved from 1.16322 to 1.16169, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 87s 582ms/step - loss: 1.1617 - lr: 0.0010\n",
      "Epoch 63/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1395\n",
      "Epoch 63: loss improved from 1.16169 to 1.13948, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 77s 512ms/step - loss: 1.1395 - lr: 0.0010\n",
      "Epoch 64/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1278\n",
      "Epoch 64: loss improved from 1.13948 to 1.12780, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 61s 407ms/step - loss: 1.1278 - lr: 0.0010\n",
      "Epoch 65/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1180\n",
      "Epoch 65: loss improved from 1.12780 to 1.11803, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 61s 408ms/step - loss: 1.1180 - lr: 0.0010\n",
      "Epoch 66/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1053\n",
      "Epoch 66: loss improved from 1.11803 to 1.10528, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 61s 407ms/step - loss: 1.1053 - lr: 0.0010\n",
      "Epoch 67/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1523\n",
      "Epoch 67: loss did not improve from 1.10528\n",
      "150/150 [==============================] - 66s 443ms/step - loss: 1.1523 - lr: 0.0010\n",
      "Epoch 68/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1488\n",
      "Epoch 68: loss did not improve from 1.10528\n",
      "150/150 [==============================] - 66s 437ms/step - loss: 1.1488 - lr: 0.0010\n",
      "Epoch 69/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1222\n",
      "Epoch 69: loss did not improve from 1.10528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "150/150 [==============================] - 65s 430ms/step - loss: 1.1222 - lr: 0.0010\n",
      "Epoch 70/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8452\n",
      "Epoch 70: loss improved from 1.10528 to 0.84522, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 69s 457ms/step - loss: 0.8452 - lr: 2.0000e-04\n",
      "Epoch 71/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7454\n",
      "Epoch 71: loss improved from 0.84522 to 0.74542, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 447ms/step - loss: 0.7454 - lr: 2.0000e-04\n",
      "Epoch 72/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7165\n",
      "Epoch 72: loss improved from 0.74542 to 0.71649, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 445ms/step - loss: 0.7165 - lr: 2.0000e-04\n",
      "Epoch 73/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7023\n",
      "Epoch 73: loss improved from 0.71649 to 0.70226, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 66s 440ms/step - loss: 0.7023 - lr: 2.0000e-04\n",
      "Epoch 74/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6960\n",
      "Epoch 74: loss improved from 0.70226 to 0.69605, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 65s 431ms/step - loss: 0.6960 - lr: 2.0000e-04\n",
      "Epoch 75/75\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6945\n",
      "Epoch 75: loss improved from 0.69605 to 0.69445, saving model to model_nwp.h5\n",
      "150/150 [==============================] - 67s 450ms/step - loss: 0.6945 - lr: 2.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x198e0f73280>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, epochs=75, callbacks = [checkpoints, reduces, tensorboard_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cf63b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--detect_file_replacement BOOL]\n",
       "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
       "                   [--whatif-data-dir PATH]\n",
       "                   {serve,dev} ...\n",
       "tensorboard: error: argument {serve,dev}: invalid choice: './logsnw' (choose from 'serve', 'dev')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir= './logsnw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26c78b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_text_next(Text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "    sequence = np.array(sequence)\n",
    "    preds = model.predict(sequence)\n",
    "    p_class = np.argmax(preds)\n",
    "    p_word = tokenizer.index_word[p_class]\n",
    "    return p_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "198e53f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter text:re-use it under the terms of the\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'project'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = input(\"enter text:\")\n",
    "text = text.split(' ')\n",
    "text = text[-1]\n",
    "text = ''.join(text)\n",
    "predictive_text_next(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8eea3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
